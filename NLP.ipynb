{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import time\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "\n",
    "data = pd.read_csv(\"data/tweets.csv\", encoding =\"ISO-8859-1\" , names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= data[data['text'].notnull()]\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "documents = dataset[\"text\"][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1    is upset that he can't update his Facebook by ...\n",
       "2    @Kenichan I dived many times for the ball. Man...\n",
       "3      my whole body feels itchy and like its on fire \n",
       "4    @nationwideclass no, it's not behaving at all....\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]\n",
    "\n",
    "data.target = data.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset labels distribution')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cnt = Counter(data.target)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar([tar for tar in target_cnt.keys()], [target_cnt[tar]for tar in target_cnt.keys()])\n",
    "plt.title(\"Dataset labels distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\F376507\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.set_proxy('http://10.225.92.1:80', user=None, password='')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmer example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample = documents[:10].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['@switchfoot', 'http://twitpic.com/2y1zl', '-', 'Awww,', \"that's\", 'a', 'bummer.', '', 'You', 'shoulda', 'got', 'David', 'Carr', 'of', 'Third', 'Day', 'to', 'do', 'it.', ';D']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['awww', 'bummer', 'shoulda', 'get', 'david', 'carr', 'day']\n"
     ]
    }
   ],
   "source": [
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [awww, bummer, shoulda, get, david, carr, day]\n",
       "1    [upset, updat, facebook, text, result, school,...\n",
       "2         [dive, time, ball, manag, save, rest, bound]\n",
       "3                            [bodi, feel, itchi, like]\n",
       "4                                         [behav, mad]\n",
       "5                                               [crew]\n",
       "6                                          [need, hug]\n",
       "7    [hey, long, time, yes, rain, bite, bite, lol, ...\n",
       "8                                               [nope]\n",
       "9                                         [que, muera]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 awww\n",
      "1 bummer\n",
      "2 carr\n",
      "3 david\n",
      "4 day\n",
      "5 get\n",
      "6 shoulda\n",
      "7 blah\n",
      "8 facebook\n",
      "9 result\n",
      "10 school\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out toke when they appearns feuw times and a lot of times\n",
    "# And then keep the 100000 more frequent tokens\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 1), (12, 1), (13, 1), (14, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 11 (\"manag\") appears 1 time.\n",
      "Word 12 (\"rest\") appears 1 time.\n",
      "Word 13 (\"save\") appears 1 time.\n",
      "Word 14 (\"time\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_2 = bow_corpus[2]\n",
    "\n",
    "for i in range(len(bow_doc_2)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_2[i][0], \n",
    "                                                     dictionary[bow_doc_2[i][0]], \n",
    "                                                     bow_doc_2[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5964669800362361),\n",
      " (1, 0.6827273885013042),\n",
      " (2, 0.2964472836056829),\n",
      " (3, 0.3003821944780571)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1 : Running LDA using Bag of Words WORST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.039*\"get\" + 0.027*\"sleep\" + 0.016*\"day\" + 0.016*\"think\" + 0.015*\"work\" + 0.014*\"tire\" + 0.013*\"wait\" + 0.013*\"bore\" + 0.011*\"omg\" + 0.011*\"need\"\n",
      "Topic: 1 \n",
      "Words: 0.043*\"good\" + 0.032*\"sorri\" + 0.032*\"miss\" + 0.025*\"day\" + 0.019*\"today\" + 0.018*\"time\" + 0.014*\"morn\" + 0.014*\"lol\" + 0.014*\"hope\" + 0.013*\"year\"\n",
      "Topic: 2 \n",
      "Words: 0.053*\"quot\" + 0.038*\"miss\" + 0.028*\"wish\" + 0.028*\"work\" + 0.024*\"night\" + 0.023*\"think\" + 0.016*\"go\" + 0.012*\"fun\" + 0.012*\"get\" + 0.012*\"day\"\n",
      "Topic: 3 \n",
      "Words: 0.026*\"know\" + 0.023*\"work\" + 0.023*\"hear\" + 0.022*\"sorri\" + 0.016*\"snow\" + 0.015*\"want\" + 0.015*\"sick\" + 0.014*\"start\" + 0.013*\"poor\" + 0.013*\"sad\"\n",
      "Topic: 4 \n",
      "Words: 0.034*\"go\" + 0.030*\"feel\" + 0.030*\"day\" + 0.026*\"like\" + 0.022*\"work\" + 0.017*\"sleep\" + 0.016*\"right\" + 0.015*\"wish\" + 0.014*\"play\" + 0.014*\"time\"\n",
      "Topic: 5 \n",
      "Words: 0.047*\"like\" + 0.035*\"day\" + 0.033*\"work\" + 0.028*\"go\" + 0.020*\"come\" + 0.018*\"feel\" + 0.017*\"quot\" + 0.013*\"tomorrow\" + 0.012*\"tri\" + 0.012*\"way\"\n",
      "Topic: 6 \n",
      "Words: 0.056*\"today\" + 0.023*\"want\" + 0.022*\"go\" + 0.020*\"work\" + 0.019*\"hate\" + 0.015*\"feel\" + 0.015*\"bad\" + 0.015*\"get\" + 0.014*\"watch\" + 0.012*\"hope\"\n",
      "Topic: 7 \n",
      "Words: 0.049*\"sad\" + 0.037*\"feel\" + 0.019*\"break\" + 0.018*\"think\" + 0.017*\"better\" + 0.015*\"get\" + 0.015*\"sick\" + 0.011*\"work\" + 0.011*\"bed\" + 0.011*\"win\"\n",
      "Topic: 8 \n",
      "Words: 0.058*\"work\" + 0.026*\"want\" + 0.023*\"get\" + 0.023*\"miss\" + 0.019*\"day\" + 0.017*\"know\" + 0.017*\"tonight\" + 0.016*\"long\" + 0.016*\"hour\" + 0.014*\"home\"\n",
      "Topic: 9 \n",
      "Words: 0.030*\"twitter\" + 0.028*\"want\" + 0.027*\"home\" + 0.023*\"love\" + 0.020*\"cold\" + 0.020*\"need\" + 0.017*\"get\" + 0.017*\"go\" + 0.014*\"friend\" + 0.014*\"night\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2 : Running LDA using TF-IDF BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.027*\"sleep\" + 0.022*\"wish\" + 0.016*\"follow\" + 0.015*\"break\" + 0.013*\"need\" + 0.011*\"drink\" + 0.010*\"school\" + 0.010*\"car\" + 0.010*\"amp\" + 0.010*\"think\"\n",
      "Topic: 1 Word: 0.030*\"twitter\" + 0.028*\"watch\" + 0.014*\"wait\" + 0.011*\"man\" + 0.011*\"quot\" + 0.011*\"eat\" + 0.011*\"send\" + 0.010*\"day\" + 0.010*\"okay\" + 0.009*\"break\"\n",
      "Topic: 2 Word: 0.043*\"want\" + 0.022*\"like\" + 0.021*\"friend\" + 0.014*\"phone\" + 0.013*\"peopl\" + 0.013*\"get\" + 0.011*\"go\" + 0.010*\"earli\" + 0.010*\"pic\" + 0.009*\"miss\"\n",
      "Topic: 3 Word: 0.019*\"go\" + 0.015*\"miss\" + 0.015*\"need\" + 0.014*\"work\" + 0.014*\"good\" + 0.014*\"home\" + 0.013*\"today\" + 0.013*\"morn\" + 0.012*\"thank\" + 0.011*\"sick\"\n",
      "Topic: 4 Word: 0.047*\"work\" + 0.035*\"feel\" + 0.015*\"sit\" + 0.014*\"good\" + 0.014*\"go\" + 0.013*\"bad\" + 0.013*\"today\" + 0.013*\"better\" + 0.012*\"ill\" + 0.011*\"time\"\n",
      "Topic: 5 Word: 0.026*\"sorri\" + 0.019*\"home\" + 0.016*\"fun\" + 0.015*\"time\" + 0.014*\"go\" + 0.014*\"class\" + 0.012*\"day\" + 0.012*\"week\" + 0.011*\"aww\" + 0.011*\"think\"\n",
      "Topic: 6 Word: 0.024*\"get\" + 0.022*\"know\" + 0.021*\"tire\" + 0.020*\"work\" + 0.018*\"night\" + 0.014*\"weekend\" + 0.013*\"hate\" + 0.013*\"leav\" + 0.012*\"bore\" + 0.012*\"thing\"\n",
      "Topic: 7 Word: 0.037*\"miss\" + 0.034*\"sad\" + 0.027*\"day\" + 0.017*\"sorri\" + 0.016*\"tomorrow\" + 0.015*\"tonight\" + 0.015*\"hear\" + 0.014*\"work\" + 0.013*\"come\" + 0.012*\"want\"\n",
      "Topic: 8 Word: 0.020*\"wanna\" + 0.017*\"work\" + 0.015*\"think\" + 0.015*\"get\" + 0.013*\"today\" + 0.013*\"feel\" + 0.011*\"hour\" + 0.011*\"night\" + 0.010*\"quot\" + 0.010*\"wait\"\n",
      "Topic: 9 Word: 0.026*\"quot\" + 0.021*\"suck\" + 0.020*\"hope\" + 0.020*\"love\" + 0.017*\"snow\" + 0.014*\"gonna\" + 0.013*\"sick\" + 0.013*\"work\" + 0.012*\"lol\" + 0.011*\"day\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dive', 'time', 'ball', 'manag', 'save', 'rest', 'bound']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8198950886726379\t \n",
      "Topic: 0.026*\"know\" + 0.023*\"work\" + 0.023*\"hear\" + 0.022*\"sorri\" + 0.016*\"snow\" + 0.015*\"want\" + 0.015*\"sick\" + 0.014*\"start\" + 0.013*\"poor\" + 0.013*\"sad\"\n",
      "\n",
      "Score: 0.02001735381782055\t \n",
      "Topic: 0.043*\"good\" + 0.032*\"sorri\" + 0.032*\"miss\" + 0.025*\"day\" + 0.019*\"today\" + 0.018*\"time\" + 0.014*\"morn\" + 0.014*\"lol\" + 0.014*\"hope\" + 0.013*\"year\"\n",
      "\n",
      "Score: 0.02001594379544258\t \n",
      "Topic: 0.047*\"like\" + 0.035*\"day\" + 0.033*\"work\" + 0.028*\"go\" + 0.020*\"come\" + 0.018*\"feel\" + 0.017*\"quot\" + 0.013*\"tomorrow\" + 0.012*\"tri\" + 0.012*\"way\"\n",
      "\n",
      "Score: 0.020012496039271355\t \n",
      "Topic: 0.034*\"go\" + 0.030*\"feel\" + 0.030*\"day\" + 0.026*\"like\" + 0.022*\"work\" + 0.017*\"sleep\" + 0.016*\"right\" + 0.015*\"wish\" + 0.014*\"play\" + 0.014*\"time\"\n",
      "\n",
      "Score: 0.020012298598885536\t \n",
      "Topic: 0.039*\"get\" + 0.027*\"sleep\" + 0.016*\"day\" + 0.016*\"think\" + 0.015*\"work\" + 0.014*\"tire\" + 0.013*\"wait\" + 0.013*\"bore\" + 0.011*\"omg\" + 0.011*\"need\"\n",
      "\n",
      "Score: 0.020010897889733315\t \n",
      "Topic: 0.030*\"twitter\" + 0.028*\"want\" + 0.027*\"home\" + 0.023*\"love\" + 0.020*\"cold\" + 0.020*\"need\" + 0.017*\"get\" + 0.017*\"go\" + 0.014*\"friend\" + 0.014*\"night\"\n",
      "\n",
      "Score: 0.020009944215416908\t \n",
      "Topic: 0.049*\"sad\" + 0.037*\"feel\" + 0.019*\"break\" + 0.018*\"think\" + 0.017*\"better\" + 0.015*\"get\" + 0.015*\"sick\" + 0.011*\"work\" + 0.011*\"bed\" + 0.011*\"win\"\n",
      "\n",
      "Score: 0.020009584724903107\t \n",
      "Topic: 0.058*\"work\" + 0.026*\"want\" + 0.023*\"get\" + 0.023*\"miss\" + 0.019*\"day\" + 0.017*\"know\" + 0.017*\"tonight\" + 0.016*\"long\" + 0.016*\"hour\" + 0.014*\"home\"\n",
      "\n",
      "Score: 0.020009063184261322\t \n",
      "Topic: 0.056*\"today\" + 0.023*\"want\" + 0.022*\"go\" + 0.020*\"work\" + 0.019*\"hate\" + 0.015*\"feel\" + 0.015*\"bad\" + 0.015*\"get\" + 0.014*\"watch\" + 0.012*\"hope\"\n",
      "\n",
      "Score: 0.020007340237498283\t \n",
      "Topic: 0.053*\"quot\" + 0.038*\"miss\" + 0.028*\"wish\" + 0.028*\"work\" + 0.024*\"night\" + 0.023*\"think\" + 0.016*\"go\" + 0.012*\"fun\" + 0.012*\"get\" + 0.012*\"day\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[2]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8199706673622131\t \n",
      "Topic: 0.026*\"sorri\" + 0.019*\"home\" + 0.016*\"fun\" + 0.015*\"time\" + 0.014*\"go\" + 0.014*\"class\" + 0.012*\"day\" + 0.012*\"week\" + 0.011*\"aww\" + 0.011*\"think\"\n",
      "\n",
      "Score: 0.020005393773317337\t \n",
      "Topic: 0.026*\"quot\" + 0.021*\"suck\" + 0.020*\"hope\" + 0.020*\"love\" + 0.017*\"snow\" + 0.014*\"gonna\" + 0.013*\"sick\" + 0.013*\"work\" + 0.012*\"lol\" + 0.011*\"day\"\n",
      "\n",
      "Score: 0.020003817975521088\t \n",
      "Topic: 0.043*\"want\" + 0.022*\"like\" + 0.021*\"friend\" + 0.014*\"phone\" + 0.013*\"peopl\" + 0.013*\"get\" + 0.011*\"go\" + 0.010*\"earli\" + 0.010*\"pic\" + 0.009*\"miss\"\n",
      "\n",
      "Score: 0.02000374346971512\t \n",
      "Topic: 0.019*\"go\" + 0.015*\"miss\" + 0.015*\"need\" + 0.014*\"work\" + 0.014*\"good\" + 0.014*\"home\" + 0.013*\"today\" + 0.013*\"morn\" + 0.012*\"thank\" + 0.011*\"sick\"\n",
      "\n",
      "Score: 0.020003413781523705\t \n",
      "Topic: 0.047*\"work\" + 0.035*\"feel\" + 0.015*\"sit\" + 0.014*\"good\" + 0.014*\"go\" + 0.013*\"bad\" + 0.013*\"today\" + 0.013*\"better\" + 0.012*\"ill\" + 0.011*\"time\"\n",
      "\n",
      "Score: 0.02000339888036251\t \n",
      "Topic: 0.030*\"twitter\" + 0.028*\"watch\" + 0.014*\"wait\" + 0.011*\"man\" + 0.011*\"quot\" + 0.011*\"eat\" + 0.011*\"send\" + 0.010*\"day\" + 0.010*\"okay\" + 0.009*\"break\"\n",
      "\n",
      "Score: 0.02000298537313938\t \n",
      "Topic: 0.027*\"sleep\" + 0.022*\"wish\" + 0.016*\"follow\" + 0.015*\"break\" + 0.013*\"need\" + 0.011*\"drink\" + 0.010*\"school\" + 0.010*\"car\" + 0.010*\"amp\" + 0.010*\"think\"\n",
      "\n",
      "Score: 0.020002679899334908\t \n",
      "Topic: 0.020*\"wanna\" + 0.017*\"work\" + 0.015*\"think\" + 0.015*\"get\" + 0.013*\"today\" + 0.013*\"feel\" + 0.011*\"hour\" + 0.011*\"night\" + 0.010*\"quot\" + 0.010*\"wait\"\n",
      "\n",
      "Score: 0.020002061501145363\t \n",
      "Topic: 0.024*\"get\" + 0.022*\"know\" + 0.021*\"tire\" + 0.020*\"work\" + 0.018*\"night\" + 0.014*\"weekend\" + 0.013*\"hate\" + 0.013*\"leav\" + 0.012*\"bore\" + 0.012*\"thing\"\n",
      "\n",
      "Score: 0.020001817494630814\t \n",
      "Topic: 0.037*\"miss\" + 0.034*\"sad\" + 0.027*\"day\" + 0.017*\"sorri\" + 0.016*\"tomorrow\" + 0.015*\"tonight\" + 0.015*\"hear\" + 0.014*\"work\" + 0.013*\"come\" + 0.012*\"want\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[2]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6998245716094971\t Topic: 0.030*\"twitter\" + 0.028*\"want\" + 0.027*\"home\" + 0.023*\"love\" + 0.020*\"cold\"\n",
      "Score: 0.03337667137384415\t Topic: 0.047*\"like\" + 0.035*\"day\" + 0.033*\"work\" + 0.028*\"go\" + 0.020*\"come\"\n",
      "Score: 0.03336497023701668\t Topic: 0.034*\"go\" + 0.030*\"feel\" + 0.030*\"day\" + 0.026*\"like\" + 0.022*\"work\"\n",
      "Score: 0.03336025029420853\t Topic: 0.043*\"good\" + 0.032*\"sorri\" + 0.032*\"miss\" + 0.025*\"day\" + 0.019*\"today\"\n",
      "Score: 0.03335464000701904\t Topic: 0.058*\"work\" + 0.026*\"want\" + 0.023*\"get\" + 0.023*\"miss\" + 0.019*\"day\"\n",
      "Score: 0.033350951969623566\t Topic: 0.039*\"get\" + 0.027*\"sleep\" + 0.016*\"day\" + 0.016*\"think\" + 0.015*\"work\"\n",
      "Score: 0.033345382660627365\t Topic: 0.053*\"quot\" + 0.038*\"miss\" + 0.028*\"wish\" + 0.028*\"work\" + 0.024*\"night\"\n",
      "Score: 0.0333435945212841\t Topic: 0.056*\"today\" + 0.023*\"want\" + 0.022*\"go\" + 0.020*\"work\" + 0.019*\"hate\"\n",
      "Score: 0.03334028273820877\t Topic: 0.049*\"sad\" + 0.037*\"feel\" + 0.019*\"break\" + 0.018*\"think\" + 0.017*\"better\"\n",
      "Score: 0.03333865851163864\t Topic: 0.026*\"know\" + 0.023*\"work\" + 0.023*\"hear\" + 0.022*\"sorri\" + 0.016*\"snow\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'I love my day'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
